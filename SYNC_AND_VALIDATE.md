# Crawly Data Validator & Sync

Script zur Validierung und Synchronisierung von Lidl-Produktdaten zwischen Datenbanken.

## ğŸ“‹ Workflow

```
Scraper â†’ crawly_lidl_db
           â†“
      [Validation]  â† PrÃ¼ft auf Fehler
           â†“
      [Sync]        â† ÃœbertrÃ¤gt saubere Daten
           â†“
      crawly_db    â† Master-DB fÃ¼r API
```

## ğŸš€ Nutzung

### Einfach starten:
```powershell
python sync_and_validate.py
```

## âœ… Validierungen

Das Script prÃ¼ft auf folgende Probleme:

| Check | Kritisch | Beschreibung |
|-------|----------|-------------|
| Fehlende Namen | âš ï¸ | Produkt ohne Namen |
| Fehlende Preise | âŒ | Produkt ohne oder mit ungÃ¼ltigem Preis |
| Fehlende SKU | âŒ | Keine eindeutige Kennung |
| Fehlende Lidl-ID | âš ï¸ | Innere Lidl-Produktkennung fehlt |
| Duplikate | âš ï¸ | Mehrfach vorhandene SKU |
| Negative Preise | âŒ | UngÃ¼ltige Preise |
| Verwaiste History | âš ï¸ | History-EintrÃ¤ge ohne Produkt |

**Legend:**
- âŒ = **Kritisch** - Sync wird abgebrochen
- âš ï¸ = **Warnung** - Wird geloggt, Sync lÃ¤uft weiter

## ğŸ“Š Output

### Bei Erfolg:
```
VALIDATION SUMMARY:
âœ… Validation PASSED - Data quality OK

SYNC PHASE: Transferring clean data to crawly_db
âœ“ Synced 96 products
âœ“ Synced 2 scraper runs

Final Statistics:
  â€¢ Products synced: 96
  â€¢ Products skipped: 0
  â€¢ Scraper runs synced: 2

âœ… crawly_db is now ready for API queries!
   96 clean products available
```

### Bei Fehler:
```
VALIDATION SUMMARY:
âŒ CRITICAL ISSUES (2):
  âŒ 5 products missing/invalid price
  âŒ 3 products missing SKU

âŒ Validation FAILED - Sync aborted
   Please fix the critical issues in crawly_lidl_db before syncing
```

## ğŸ”„ Workflow-Beispiel

```powershell
# 1. Scraper lÃ¤uft und fÃ¼llt crawly_lidl_db
python run_scraper.py --max-pages 10

# 2. Validieren & Synchronisieren
python sync_and_validate.py

# 3. API liest saubere Daten aus crawly_db
curl http://localhost:8001/products
```

## ğŸ“ Konfiguration

Umgebungsvariablen (optional):

```powershell
# Lidl-Datenbank (wo Scraper schreibt)
$env:LIDL_DATABASE_URL="mysql+pymysql://crawly_user:***@localhost:3306/crawly_lidl_db"

# Master-Datenbank (wo API liest)
$env:MASTER_DATABASE_URL="mysql+pymysql://crawly_user:***@localhost:3306/crawly_db"

# Dann Script starten
python sync_and_validate.py
```

## ğŸ¯ Was passiert beim Sync

1. **crawly_db wird geleert** - Alte Daten werden gelÃ¶scht
2. **Produkte werden transferiert**:
   - Nur Produkte mit valid SKU + Price
   - Duplikate werden gefiltert
   - NULL-Werte werden korrigiert
3. **Metadaten werden kopiert** - ScraperRun-Informationen
4. **Datenbank ist ready** - API kann abfragen

## ğŸ” Fehler beheben

### Problem: "CRITICAL ISSUES - Sync aborted"

**LÃ¶sung:** crawly_lidl_db direkt reparieren:

```sql
-- Produkte ohne Preis lÃ¶schen
DELETE FROM crawly_lidl_db.products WHERE price IS NULL OR price <= 0;

-- Produkte ohne SKU lÃ¶schen
DELETE FROM crawly_lidl_db.products WHERE sku IS NULL OR sku = '';

-- Duplikate bereinigen (letzte Version behalten)
DELETE p1 FROM crawly_lidl_db.products p1
INNER JOIN crawly_lidl_db.products p2
WHERE p1.id > p2.id AND p1.sku = p2.sku;
```

Dann nochmal `sync_and_validate.py` starten.

## ğŸ“ˆ NÃ¤chste Schritte

- [ ] Amazon-Scraper hinzufÃ¼gen â†’ `crawly_amazon_db`
- [ ] eBay-Scraper hinzufÃ¼gen â†’ `crawly_ebay_db`
- [ ] Aggregations-Script erweitern fÃ¼r mehrere Quellen
- [ ] API-Endpoints fÃ¼r Quellen-Filter hinzufÃ¼gen

---

**Hinweis:** Dieses Script ist Teil des Crawly-Datenmanagement-Systems. Es sollte nach jedem Scraper-Lauf ausgefÃ¼hrt werden, um DatenintegritÃ¤t zu gewÃ¤hrleisten.
